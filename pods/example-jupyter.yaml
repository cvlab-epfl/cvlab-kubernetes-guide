apiVersion: v1
kind: Pod
metadata:
  name: username-example-jupyter
  labels:
    user: set-your-username
spec:
  restartPolicy: Never
  containers:
    - name: jupyter-server
      image: ic-registry.epfl.ch/cvlab/lis/lab-python-ml:cuda10
      #command: ["/opt/lab/setup_and_wait.sh"] 
      #   this one will do nothing and wait, so you can enter the container yourself with
      #   kubectl exec -it pod_name /bin/bash
      
      command:
      - "/opt/lab/setup_and_run_command.sh"
      - "jupyter lab --ip=0.0.0.0 --no-browser --notebook-dir=/cvlabdata2/home/lis/kubernetes_example"
      # runs the command on the 2nd line

      env:
      - name: CLUSTER_USER
        value: "username" # set this
      - name: CLUSTER_USER_ID
      # set this, run `id` on cvlab cluster to get the number, it will print among other things:
      # uid=number(yourname)
        value: "12345" 
      - name: CLUSTER_GROUP_NAME
        value: "CVLAB-unit"
      - name: CLUSTER_GROUP_ID
        value: "11166"
      - name: JUPYTER_CONFIG_DIR
        value: "/cvlabdata2/home/lis/kubernetes_example/.jupyter"

      ports:
        - containerPort: 8888
          name: jupyter
          
      volumeMounts:
        - mountPath: /cvlabsrc1
          name: cvlabsrc1
        - mountPath: /cvlabdata1
          name: cvlabdata1
        - mountPath: /cvlabdata2
          name: cvlabdata2
        - mountPath: /dev/shm
          name: dshm

      # specify that it uses a GPU!
      # resources:
      #   limits:
      #     nvidia.com/gpu: 1 # requesting 1 GPU
  
  volumes:
    - name: cvlabsrc1
      persistentVolumeClaim:
        claimName: pv-cvlabsrc1

    - name: cvlabdata1
      persistentVolumeClaim:
        claimName: pv-cvlabdata1

    - name: cvlabdata2
      persistentVolumeClaim:
        claimName: pv-cvlabdata2

    # shared memory, often needed by PyTorch dataloaders
    - name: dshm
      emptyDir:
        medium: Memory
        sizeLimit: 8Gi
